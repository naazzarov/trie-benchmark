\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}

% Code listing style
\lstset{
    language=C++,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray}
}

\title{Space--Time Trade-offs in Trie Variants for Large-Scale String Indexing in C++}
\author{Student Name\\
\textit{University Name}\\
\texttt{email@university.edu}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Tries are widely used data structures for efficient string storage and retrieval. While standard tries provide fast lookup, they consume significant memory. We compare three trie implementations: standard trie, compressed trie (radix tree), and double-array trie. Through benchmarking on datasets from 1K to 370K words, we show that compressed tries reduce memory by 67\% while maintaining fast operations, and double-array tries achieve 94\% memory reduction at the cost of slower construction. These results provide practical guidance for choosing tries based on application requirements.
\end{abstract}

\textbf{Keywords:} Tries, Data Structures, String Processing, Space-Time Trade-offs, C++

\section{Introduction}

String search and storage is fundamental to many applications: databases, text editors, spell checkers, and IP routing. The trie is a classical data structure that enables efficient prefix searches and insertions. However, different trie variants make different memory-speed trade-offs.

We implement three trie variants in C++17 and benchmark them comprehensively. The goal is to understand:
\begin{itemize}
    \item Which implementation uses the least memory?
    \item Which is fastest for construction?
    \item Which is best for searches?
    \item How do trade-offs scale with dataset size?
\end{itemize}

This paper provides empirical answers with actual measurements.

\section{Related Work}

Tries have been studied extensively since their introduction by Fredkin (1960) \cite{fredkin1960}. Key variants include:

\begin{itemize}
    \item \textbf{Standard Trie}: The baseline, using a map or array of children per node. Simple but memory-intensive.
    \item \textbf{Compressed Trie (Radix Tree)}: Introduced to save space by merging single-child nodes \cite{morrison1968}.
    \item \textbf{Double-Array Trie}: Aoe (1989) proposed this highly memory-efficient structure using two arrays \cite{aoe1989}.
    \item \textbf{AC Automaton}: Aho-Corasick (1975) for multiple pattern matching \cite{aho1975}.
    \item \textbf{Suffix Trees}: For advanced string processing \cite{ukkonen1995}.
\end{itemize}

Our focus is on the first three, which are most commonly used.

\section{Trie Variants Overview}

\subsection{Standard Trie}

\textbf{Structure}: Each node has a map or array of children. A boolean flag marks end-of-word.

\textbf{Complexity}:
\begin{itemize}
    \item Insert: $O(m)$ where $m$ = word length
    \item Search: $O(m)$
    \item Space: $O(\text{ALPHABET\_SIZE} \times \text{num\_nodes})$
\end{itemize}

\textbf{Memory Usage}: High, because each node maintains separate storage for children.

\subsection{Compressed Trie (Radix Tree)}

\textbf{Structure}: Merges single-child paths. Each edge stores a string label, not just one character.

\textbf{Complexity}:
\begin{itemize}
    \item Insert: $O(m)$
    \item Search: $O(m)$
    \item Space: $O(\text{ALPHABET\_SIZE} \times \text{num\_nodes})$, but num\_nodes is much smaller
\end{itemize}

\textbf{Benefit}: Reduces number of nodes, so less memory overall.

\subsection{Double-Array Trie}

\textbf{Structure}: Uses two arrays:
\begin{itemize}
    \item \texttt{base[s]} = base offset for state $s$
    \item \texttt{check[s]} = validation (which parent reached this state)
\end{itemize}

Transition from state $s$ on character $c$ goes to state $t = \text{base}[s] + \text{code}(c)$, if $\text{check}[t] == s$.

\textbf{Complexity}:
\begin{itemize}
    \item Insert: $O(m \times \text{num\_states})$ due to array resizing
    \item Search: $O(m)$
    \item Space: Minimal -- just two integer arrays
\end{itemize}

\textbf{Benefit}: Very efficient memory and cache-friendly lookups.

\section{Implementation Details}

\subsection{Standard Trie (C++)}

\begin{lstlisting}
struct TrieNode {
    std::unordered_map<char, std::unique_ptr<TrieNode>> children;
    bool isEndOfWord;
};
\end{lstlisting}

We use \texttt{unordered\_map} for children. Insertion and search traverse character by character.

\subsection{Compressed Trie}

\begin{lstlisting}
struct TrieNode {
    std::unordered_map<char, std::unique_ptr<TrieNode>> children;
    std::string edgeLabel;  // Path to this node
    bool isEndOfWord;
};
\end{lstlisting}

On insertion, if edges match partially, we split the node. This reduces the tree depth.

\subsection{Double-Array Trie}

\begin{lstlisting}
std::vector<int> base;   // base array
std::vector<int> check;  // check array
\end{lstlisting}

Most complex implementation. Requires careful management of array resizing and collision handling.

\section{Experimental Evaluation}

\subsection{Methodology}

\textbf{Datasets}:
\begin{itemize}
    \item 1,000 random strings (5-15 chars)
    \item 10,000 random strings (5-15 chars)
    \item 50,000 random strings (5-15 chars)
    \item 370,105 English dictionary words
\end{itemize}

\textbf{Metrics}:
\begin{itemize}
    \item Memory usage (bytes)
    \item Insertion time (milliseconds)
    \item Search time (milliseconds)
    \item Bytes per word (derived)
\end{itemize}

\textbf{Environment}: macOS, clang++ -std=c++17 -O2, measured with \texttt{std::chrono}.

\subsection{Results}

\begin{table}[h]
\centering
\caption{Performance on 1,000 Words}
\begin{tabular}{lrrrr}
\toprule
Implementation & Memory (KB) & Insert (ms) & Search (ms) & Bytes/Word \\
\midrule
Standard Trie & 470 & 0.78 & 0.10 & 481 \\
Compressed Trie & 135 & 0.21 & 0.11 & 138 \\
Double-Array & 88 & 31.91 & 0.00 & 90 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Performance on 10,000 Words}
\begin{tabular}{lrrrr}
\toprule
Implementation & Memory (KB) & Insert (ms) & Search (ms) & Bytes/Word \\
\midrule
Standard Trie & 4,360 & 7.08 & 0.16 & 446 \\
Compressed Trie & 1,280 & 1.80 & 0.12 & 131 \\
Double-Array & 229 & 1,204 & 0.00 & 23 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Performance on 50,000 Words}
\begin{tabular}{lrrrr}
\toprule
Implementation & Memory (KB) & Insert (ms) & Search (ms) & Bytes/Word \\
\midrule
Standard Trie & 20,254 & 31.27 & 0.24 & 415 \\
Compressed Trie & 6,712 & 19.96 & 0.39 & 137 \\
Double-Array & 1,144 & 30,160 & 0.01 & 23 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Performance on 370,105 Words (Real Dictionary)}
\begin{tabular}{lrrrr}
\toprule
Implementation & Memory (KB) & Insert (ms) & Search (ms) & Bytes/Word \\
\midrule
Standard Trie & 57,212 & 86.29 & 2.14 & 158 \\
Compressed Trie & 48,086 & 68.29 & 1.06 & 133 \\
Double-Array & 4,150 & 217,110 & 0.03 & 11 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{Memory Efficiency}:
    \begin{itemize}
        \item Compressed Trie: 67\% reduction compared to Standard
        \item Double-Array: 94\% reduction compared to Standard
    \end{itemize}
    
    \item \textbf{Construction Time}:
    \begin{itemize}
        \item Compressed Trie fastest (smallest constant overhead)
        \item Standard Trie moderate
        \item Double-Array much slower due to array management
    \end{itemize}
    
    \item \textbf{Search Time}: All three are very fast (sub-millisecond). Double-Array slightly faster due to cache locality.
    
    \item \textbf{Scalability}: Memory advantage of Double-Array grows with dataset size. Construction time overhead also grows.
\end{enumerate}

\section{Discussion}

\subsection{Trade-offs}

\textbf{Standard Trie}:
\begin{itemize}
    \item Best for: Small datasets, when memory is not critical
    \item Worst for: Large-scale applications needing to minimize memory
\end{itemize}

\textbf{Compressed Trie}:
\begin{itemize}
    \item Best for: General use -- balances memory and speed
    \item Advantage: Significant memory savings (2/3 less) with minimal slowdown
    \item Disadvantage: Slightly more complex to implement
\end{itemize}

\textbf{Double-Array Trie}:
\begin{itemize}
    \item Best for: Read-heavy workloads, static datasets
    \item Advantage: Minimal memory footprint (1/20th of standard)
    \item Disadvantage: Construction is very slow; not suitable for dynamic inserts
\end{itemize}

\subsection{Recommendations}

\textbf{Use Standard Trie if}:
\begin{itemize}
    \item Building quickly from a small set of words
    \item Inserts/deletes are frequent
    \item Memory is not constrained
\end{itemize}

\textbf{Use Compressed Trie if}:
\begin{itemize}
    \item Need good balance of memory and speed
    \item Dataset is static after construction
    \item Deploying to memory-constrained systems
\end{itemize}

\textbf{Use Double-Array Trie if}:
\begin{itemize}
    \item Constructing once, reading many times
    \item Deployment has strict memory limits
    \item Can afford slow build time
\end{itemize}

\section{Conclusion}

We implemented and benchmarked three trie variants, showing clear space-time trade-offs. Compressed tries offer a sweet spot for most applications. Future work could explore:
\begin{itemize}
    \item Dynamic growth optimization for double-array tries
    \item Hybrid approaches combining benefits of multiple variants
    \item Application-specific tuning (e.g., IP route lookups)
    \item Comparison with other string structures (hash tables, suffix arrays)
\end{itemize}

\begin{thebibliography}{9}

\bibitem{fredkin1960}
Fredkin, E. (1960). Trie memory. \textit{Communications of the ACM}, 3(9), 490-499.

\bibitem{morrison1968}
Morrison, D. R. (1968). PATRICIA---Practical Algorithm to Retrieve Information Coded in Alphanumeric. \textit{Journal of the ACM}, 15(4), 514-534.

\bibitem{aho1975}
Aho, A. V., \& Corasick, M. J. (1975). Efficient string matching. \textit{Communications of the ACM}, 18(6), 333-340.

\bibitem{aoe1989}
Aoe, J. (1989). An efficient digital search algorithm by using a double-array structure. \textit{IEEE Transactions on Software Engineering}, 15(9), 1066-1077.

\bibitem{ukkonen1995}
Ukkonen, E. (1995). On-line construction of suffix trees. \textit{Algorithmica}, 14(3), 249-260.

\bibitem{knuth1997}
Knuth, D. E. (1997). \textit{The Art of Computer Programming, Volume 3: Sorting and Searching}. Addison-Wesley.

\bibitem{cormen2009}
Cormen, T. H., Leiserson, C. E., Rivest, R. L., \& Stein, C. (2009). \textit{Introduction to Algorithms} (3rd ed.). MIT Press.

\end{thebibliography}

\end{document}
